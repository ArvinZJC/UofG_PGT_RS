{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inwi1o3992TW"
      },
      "source": [
        "# Exerise 2\n",
        "\n",
        "The aims of this execise are to:\n",
        "\n",
        " - Make your first recommender by implementing a user-based CF (c.f. Lecture 4).\n",
        " - Make your first recommendations using Spotlight recommender toolkit on explicit data (Lecture 8).\n",
        " - Develop and evaluate baseline recommender systems (c.f. Lecture 3).\n",
        " - Start to think about explicit vs implicit learners.\n",
        " - Evaluate your results using Spotlight (Lecture 6 & 7).\n",
        "\n",
        "This exercise builds on the lectures' material, namely Lectures 3, 4, 6, 7 and 8.\n",
        "\n",
        "There are 10 tasks to increase your understanding of the content of the Recommender Sytems course.  Each of these tasks have corresponding questions in the quiz.\n",
        "\n",
        "We're going to use the Spotlight library in Parts B & C - see https://github.com/maciejkula/spotlight - and its documentation at https://maciejkula.github.io/spotlight/. You can install this direct from Git, but using Craig's patched version as done below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7o6MEXDajRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94231fc1-64e6-48e1-e7be-c42379f63e2f"
      },
      "source": [
        "!pip install git+https://github.com/cmacdonald/spotlight.git@master#egg=spotlight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spotlight\n",
            "  Cloning https://github.com/cmacdonald/spotlight.git (to revision master) to /tmp/pip-install-fnbxcg_t/spotlight_aa6350673b8441149d29a7978c4b893a\n",
            "  Running command git clone -q https://github.com/cmacdonald/spotlight.git /tmp/pip-install-fnbxcg_t/spotlight_aa6350673b8441149d29a7978c4b893a\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spotlight) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->spotlight) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys992pU79yhD"
      },
      "source": [
        "# Import modules.\n",
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "from typing import List, Tuple\n",
        "import time\n",
        "\n",
        "from scipy.stats import rankdata\n",
        "from spotlight.cross_validation import random_train_test_split\n",
        "from spotlight.evaluation import mrr_score, rmse_score\n",
        "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
        "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
        "from spotlight.interactions import Interactions\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "SEED = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Vlbi9W-d2j"
      },
      "source": [
        "We'll be using Movielens again. Let's load it in to the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg093kVRAvHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf2a46e-a0e8-4d24-8e9e-9bc127337b86"
      },
      "source": [
        "!curl -o ml-latest-small.zip http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "# !curl -o ml-latest-small.zip http://www.dcs.gla.ac.uk/~craigm/recsysHM/ml-latest-small.zip  # Backup location. Use it instead of the previous line if necessary.\n",
        "!unzip -o ml-latest-small.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  955k  100  955k    0     0  2834k      0 --:--:-- --:--:-- --:--:-- 2826k\n",
            "Archive:  ml-latest-small.zip\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yss68U_EA0w2"
      },
      "source": [
        "ratings_df = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "movies_df = pd.read_csv('ml-latest-small/movies.csv')\n",
        "\n",
        "# Treat userId as strings, and similarly as movies. This will prevent confusion later on.\n",
        "ratings_df['userId'] = 'u' + ratings_df['userId'].astype(str)\n",
        "ratings_df['movieId'] = 'm' + ratings_df['movieId'].astype(str)\n",
        "movies_df['movieId'] = 'm' +  movies_df['movieId'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5QQBZ3QS2Hv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "3d88d98b-13ec-49aa-b910-81ab69fe4ca7"
      },
      "source": [
        "ratings_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u1</td>\n",
              "      <td>m1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u1</td>\n",
              "      <td>m3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u1</td>\n",
              "      <td>m6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u1</td>\n",
              "      <td>m47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u1</td>\n",
              "      <td>m50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100831</th>\n",
              "      <td>u610</td>\n",
              "      <td>m166534</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1493848402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100832</th>\n",
              "      <td>u610</td>\n",
              "      <td>m168248</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1493850091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100833</th>\n",
              "      <td>u610</td>\n",
              "      <td>m168250</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1494273047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100834</th>\n",
              "      <td>u610</td>\n",
              "      <td>m168252</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1493846352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100835</th>\n",
              "      <td>u610</td>\n",
              "      <td>m170875</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1493846415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100836 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       userId  movieId  rating   timestamp\n",
              "0          u1       m1     4.0   964982703\n",
              "1          u1       m3     4.0   964981247\n",
              "2          u1       m6     4.0   964982224\n",
              "3          u1      m47     5.0   964983815\n",
              "4          u1      m50     5.0   964982931\n",
              "...       ...      ...     ...         ...\n",
              "100831   u610  m166534     4.0  1493848402\n",
              "100832   u610  m168248     5.0  1493850091\n",
              "100833   u610  m168250     5.0  1494273047\n",
              "100834   u610  m168252     5.0  1493846352\n",
              "100835   u610  m170875     3.0  1493846415\n",
              "\n",
              "[100836 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMfsveWjS4xP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "f4fb08bc-2f27-4526-b864-dab843cd267e"
      },
      "source": [
        "movies_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>m1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>m4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>m5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9737</th>\n",
              "      <td>m193581</td>\n",
              "      <td>Black Butler: Book of the Atlantic (2017)</td>\n",
              "      <td>Action|Animation|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9738</th>\n",
              "      <td>m193583</td>\n",
              "      <td>No Game No Life: Zero (2017)</td>\n",
              "      <td>Animation|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9739</th>\n",
              "      <td>m193585</td>\n",
              "      <td>Flint (2017)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9740</th>\n",
              "      <td>m193587</td>\n",
              "      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n",
              "      <td>Action|Animation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9741</th>\n",
              "      <td>m193609</td>\n",
              "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9742 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      movieId  ...                                       genres\n",
              "0          m1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1          m2  ...                   Adventure|Children|Fantasy\n",
              "2          m3  ...                               Comedy|Romance\n",
              "3          m4  ...                         Comedy|Drama|Romance\n",
              "4          m5  ...                                       Comedy\n",
              "...       ...  ...                                          ...\n",
              "9737  m193581  ...              Action|Animation|Comedy|Fantasy\n",
              "9738  m193583  ...                     Animation|Comedy|Fantasy\n",
              "9739  m193585  ...                                        Drama\n",
              "9740  m193587  ...                             Action|Animation\n",
              "9741  m193609  ...                                       Comedy\n",
              "\n",
              "[9742 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rAIXwDoBCda"
      },
      "source": [
        "# Part A. User-based CF\n",
        "\n",
        "You can generate a matrix of ratings with the `ratings_df` dataframe. In the matrix, the unrated items are filled with 0 (this means they have no impact upon the calculated cosine value)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKsmW549BNlq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "7d64ffb6-6bbd-4da8-9024-9e488e6955c9"
      },
      "source": [
        "r_df_matrix = ratings_df.pivot_table(index = 'userId', columns = 'movieId', values = 'rating').fillna(0)\n",
        "r_df_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>movieId</th>\n",
              "      <th>m1</th>\n",
              "      <th>m10</th>\n",
              "      <th>m100</th>\n",
              "      <th>m100044</th>\n",
              "      <th>m100068</th>\n",
              "      <th>m100083</th>\n",
              "      <th>m100106</th>\n",
              "      <th>m100159</th>\n",
              "      <th>m100163</th>\n",
              "      <th>m100194</th>\n",
              "      <th>m100226</th>\n",
              "      <th>m100277</th>\n",
              "      <th>m1003</th>\n",
              "      <th>m100302</th>\n",
              "      <th>m100304</th>\n",
              "      <th>m100306</th>\n",
              "      <th>m100326</th>\n",
              "      <th>m100383</th>\n",
              "      <th>m100390</th>\n",
              "      <th>m100397</th>\n",
              "      <th>m1004</th>\n",
              "      <th>m100487</th>\n",
              "      <th>m100498</th>\n",
              "      <th>m1005</th>\n",
              "      <th>m100507</th>\n",
              "      <th>m100527</th>\n",
              "      <th>m100553</th>\n",
              "      <th>m100556</th>\n",
              "      <th>m100579</th>\n",
              "      <th>m1006</th>\n",
              "      <th>m100611</th>\n",
              "      <th>m1007</th>\n",
              "      <th>m100714</th>\n",
              "      <th>m100737</th>\n",
              "      <th>m1008</th>\n",
              "      <th>m100810</th>\n",
              "      <th>m100843</th>\n",
              "      <th>m100882</th>\n",
              "      <th>m1009</th>\n",
              "      <th>m100906</th>\n",
              "      <th>...</th>\n",
              "      <th>m98836</th>\n",
              "      <th>m98908</th>\n",
              "      <th>m98961</th>\n",
              "      <th>m99</th>\n",
              "      <th>m990</th>\n",
              "      <th>m99005</th>\n",
              "      <th>m99007</th>\n",
              "      <th>m99030</th>\n",
              "      <th>m99087</th>\n",
              "      <th>m991</th>\n",
              "      <th>m99106</th>\n",
              "      <th>m99112</th>\n",
              "      <th>m99114</th>\n",
              "      <th>m99117</th>\n",
              "      <th>m99122</th>\n",
              "      <th>m99130</th>\n",
              "      <th>m99145</th>\n",
              "      <th>m99149</th>\n",
              "      <th>m99191</th>\n",
              "      <th>m993</th>\n",
              "      <th>m994</th>\n",
              "      <th>m99415</th>\n",
              "      <th>m99437</th>\n",
              "      <th>m99532</th>\n",
              "      <th>m99574</th>\n",
              "      <th>m996</th>\n",
              "      <th>m99636</th>\n",
              "      <th>m99638</th>\n",
              "      <th>m99721</th>\n",
              "      <th>m99728</th>\n",
              "      <th>m99750</th>\n",
              "      <th>m99764</th>\n",
              "      <th>m998</th>\n",
              "      <th>m99813</th>\n",
              "      <th>m99846</th>\n",
              "      <th>m99853</th>\n",
              "      <th>m999</th>\n",
              "      <th>m99910</th>\n",
              "      <th>m99917</th>\n",
              "      <th>m99992</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>u1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u100</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u101</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u102</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u95</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u96</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u97</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u98</th>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u99</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>610 rows × 9724 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "movieId   m1  m10  m100  m100044  m100068  ...  m99853  m999  m99910  m99917  m99992\n",
              "userId                                     ...                                      \n",
              "u1       4.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u10      0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u100     0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u101     0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u102     0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "...      ...  ...   ...      ...      ...  ...     ...   ...     ...     ...     ...\n",
              "u95      0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u96      5.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u97      0.0  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u98      4.5  0.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "u99      0.0  4.0   0.0      0.0      0.0  ...     0.0   0.0     0.0     0.0     0.0\n",
              "\n",
              "[610 rows x 9724 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpJXEqQ_BKxg"
      },
      "source": [
        "The left hand bold column is the [index of the dataframe](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) - that is, an attribute of the dataframe that allows fast lookup of rows. In this case, userId has become our index column.\n",
        "\n",
        "You can get all the index of users using the `.index`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRIXYwQgBRt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e648f968-33bb-4dea-e9df-ece0c0c12949"
      },
      "source": [
        "r_df_matrix.index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['u1', 'u10', 'u100', 'u101', 'u102', 'u103', 'u104', 'u105', 'u106',\n",
              "       'u107',\n",
              "       ...\n",
              "       'u90', 'u91', 'u92', 'u93', 'u94', 'u95', 'u96', 'u97', 'u98', 'u99'],\n",
              "      dtype='object', name='userId', length=610)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8RcZo1bBU8O"
      },
      "source": [
        "You can also use [`.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) to access rows, by their \"index\". For instance, we can get all ratings of a specific user with `userId` u1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77XOSOdqBXmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3fe3e8-1ada-48de-87b0-8ceb9303b785"
      },
      "source": [
        "r_df_matrix.loc['u1']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "movieId\n",
              "m1         4.0\n",
              "m10        0.0\n",
              "m100       0.0\n",
              "m100044    0.0\n",
              "m100068    0.0\n",
              "          ... \n",
              "m99853     0.0\n",
              "m999       0.0\n",
              "m99910     0.0\n",
              "m99917     0.0\n",
              "m99992     0.0\n",
              "Name: u1, Length: 9724, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt9_SlC4Beut"
      },
      "source": [
        "User-based CF heavily relies upon cosine similarity. We are providing a cosine similarity implementation based on numpy operations. We also show how to use `df.loc` to get all the ratings of a given user from `r_df_matrix` as a Series - we then make this into a numpy array using the [`.values`](https://pandas.pydata.org/docs/reference/api/pandas.Series.values.html) property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NXXbCQsBbJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff38be91-7c46-4ab6-c9a3-b7003ae35291"
      },
      "source": [
        "def cos_sim(a, b) -> float:\n",
        "  '''\n",
        "  Compute cosine similarity between two users' rating matrices.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  a : a user's rating matrix\n",
        "  b : another user's rating matrix\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  cos_sim : the cosine similarity between two users' rating matrices\n",
        "  '''\n",
        "\n",
        "  return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "\n",
        "print('Cosine similarity between userId u1 and itself:', cos_sim(r_df_matrix.loc['u1'].values, r_df_matrix.loc['u1'].values))\n",
        "print('Cosine similarity between userId u1 and userId u607:', cos_sim(r_df_matrix.loc['u1'].values, r_df_matrix.loc['u607'].values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between userId u1 and itself: 1.0\n",
            "Cosine similarity between userId u1 and userId u607: 0.2693892401115333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B061AiTiBlWJ"
      },
      "source": [
        "## Task 1. Getting the most similar users\n",
        "\n",
        "User-based CF is based on user-neighbourhoods. In this task, you will implement a function `get_most_similar_users()` that will identify the `userId` of the `k` most similar users to the specified `userId`, and their corresponding cosine similarities. \n",
        "\n",
        "In determining the most similar users, you should break ties based on their position in the array - for instance, if two users are tied as 2nd most similar user, the user who appears earlier should be 2nd, and the latter user third.\n",
        "\n",
        "You should exclude the compared user itself when generating a list of the most similar users.\n",
        "\n",
        "**Hints:** \n",
        "- The `cos_sim()` function should be used here. \n",
        "- Higher cosine similarity means more similar.\n",
        "- Try SciPy's [`rankdata()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html) function. Given an array, `rankdata()` tells you positions in sorted rank order. For instance:\n",
        "```\n",
        ">>> rankdata([5.9, 2.1, 4.3])\n",
        "array([3., 1., 2.])\n",
        "```\n",
        "It also has support for addressing ties.\n",
        "- The first return component of [np.nonzero()](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html) can be used to return the indices of the elements that are non-zero. E.g.\n",
        "```\n",
        ">>> np.array([True,False]).nonzero()[0]\n",
        "array([0])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj1wpnS7BbMF"
      },
      "source": [
        "def get_most_similar_users(user_id: str, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n",
        "  '''\n",
        "  Get top k users and cosine similarities.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  user_id : the userId of the compared user\n",
        "  k : the number of top users and cosine similarities kept\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  top_k : a tuple containing two ndarrays of top k users and cosine similarities.\n",
        "  '''\n",
        "\n",
        "  top_k_users = r_df_matrix.index[r_df_matrix.index != user_id]  # An unsorted ndarray of userId of top k users excluding the compared user.\n",
        "  top_k_cos = np.array([cos_sim(r_df_matrix.loc[user_id].values, r_df_matrix.loc[user].values) for user in top_k_users])  # An unsorted ndarray of top k cosine similarities with the same initial order as top_k_users.\n",
        "  rank = np.argsort(-top_k_cos)  # Get the indices to sort an array as per cosine similarities from the highest to the lowest.\n",
        "  return (top_k_users[rank][:k], top_k_cos[rank][:k])  # Rank users and cosine similarities, and return top k."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3jnW2BCAIWR"
      },
      "source": [
        "What is the `userId` and cosine similarity of the most similar user to `userId` u10? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVnsPTKjzqnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbfe2f0c-b51c-4eed-ac73-fe842f8bc51a"
      },
      "source": [
        "print(get_most_similar_users('u10', 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Index(['u159'], dtype='object', name='userId'), array([0.28826463]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGnAAIChA86Q"
      },
      "source": [
        "What is the cosine similarity of the 2nd most similar user to `userId` u500? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIMwvzqJ2YuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de510625-d2de-497b-9edf-9e1fc5773613"
      },
      "source": [
        "print(get_most_similar_users('u500', 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Index(['u453', 'u45'], dtype='object', name='userId'), array([0.27983214, 0.26236875]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9ZepSCnBwc7"
      },
      "source": [
        "## Task 2. Predicting ratings via user-based CF\n",
        "\n",
        "Now you should implement your user-based CF, within a `predict_rating()` function. The aim of this function is to predict the rating of a given `userId` for a given `movieId`. Your implementation should make use of your `get_most_similar_users()` implementation above, using `k` = 10 nearest neighbours.\n",
        "\n",
        "**Hint:**\n",
        "- You may wish to revise user-based CF from Lecture 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eX33RkTBbS2"
      },
      "source": [
        "def predict_rating(user_id: str, movie_id: str) -> float:\n",
        "  '''\n",
        "  Predict a specific user's rating to a specific movie using weighted average by similarity.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  user_id : the userId of the user\n",
        "  movie_id : the movieId of the movie\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  predicted : the predicted rating (0 if no existing ratings for a specific movie from similar users)\n",
        "  '''\n",
        "\n",
        "  similar_users, cos = get_most_similar_users(user_id)  # Get top 10 users and cosine similarities.\n",
        "  movie_ratings = np.array([r_df_matrix.loc[user][movie_id] for user in similar_users])  # Get specific movie ratings corresponding to the top 10 users.\n",
        "  valid_users = np.nonzero(movie_ratings)[0]  # Filter out the users whose movie rating is 0 (unknown).\n",
        "  return 0 if valid_users.size == 0 else np.sum([cos[valid_users] * movie_ratings[valid_users]]) / np.sum(cos[valid_users])  # Predict the rating using weighted average by similarity."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcOxkpymBQ0L"
      },
      "source": [
        "What is the predicted rating of `userId` u1 for `movieId` m1?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmek5k91G66m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664f19c2-41a9-4957-df87-ebcf7b697882"
      },
      "source": [
        "print('Predicted rating:', predict_rating('u1', 'm1'))\n",
        "print('Actual rating:', r_df_matrix.loc['u1']['m1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted rating: 3.898822026597358\n",
            "Actual rating: 4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuWLuAZzB9br"
      },
      "source": [
        "You can complete answering the quiz questions for Task 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqfUghVsCA7G"
      },
      "source": [
        "## Task 3. Predicting ratings via user-based CF with mean-centring normalisation\n",
        "\n",
        "Users usually rate differently. Some rate high, while others low. Some use more of the scale than others. However, the user-based CF we implemented above ignores these differences. To this end, we can apply normalisation to compensate. In this task, you will implement user-based CF with mean-centring normalisation - the functions `mean_rating()` and `predict_rating_MC()`.\n",
        "\n",
        "**Hints:**\n",
        "- See lecture 4 about user-based CF with Mean-center normalisation. \n",
        "- Check if the predicted rating for a given user makes sense (i.e. what did the user rate before)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q5Efb4zB5_O"
      },
      "source": [
        "def mean_rating(user_id: str) -> float:\n",
        "  '''\n",
        "  Compute the mean of a user's ratings.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  user_id : the userId of the user\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  rating_mean : the mean of a user's ratings\n",
        "  '''\n",
        "\n",
        "  return ratings_df[ratings_df['userId'] == user_id]['rating'].mean()  # Consider the mean of a user's known ratings.\n",
        "\n",
        "def predict_rating_MC(user_id: str, movie_id: str) -> float:\n",
        "  '''\n",
        "  Predict a specific user's rating to a specific movie using weighted average by similarity and mean-centring.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  user_id : the userId of the user\n",
        "  movie_id : the movieId of the movie\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  predicted : the predicted rating (0 if no existing ratings for a specific movie from similar users)\n",
        "  '''\n",
        "\n",
        "  similar_users, cos = get_most_similar_users(user_id)  # Get top 10 users and cosine similarities.\n",
        "  movie_ratings = np.array([r_df_matrix.loc[user][movie_id] for user in similar_users])  # Get specific movie ratings corresponding to the top 10 users.\n",
        "  valid_users = np.nonzero(movie_ratings)[0]  # Filter out the users whose movie rating is 0 (unknown).\n",
        "\n",
        "  if valid_users.size:\n",
        "    mean_ratings = np.array([mean_rating(user) for user in similar_users[valid_users]])  # Get the mean ratings for valid users.\n",
        "    return mean_rating(user_id) + np.sum([cos[valid_users] * (movie_ratings[valid_users] - mean_ratings)]) / np.sum(cos[valid_users])  # Predict the rating using weighted average by similarity and mean-centring.\n",
        "  \n",
        "  return 0  # Return 0 if no valid users."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5H431STFapG"
      },
      "source": [
        "What is the mean rating of user u5?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC_ljrU6FcpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1309413-b0d9-46cf-9b6e-302f1885fdda"
      },
      "source": [
        "print('Mean rating:', mean_rating('u5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean rating: 3.6363636363636362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waa6mvXPGM1N"
      },
      "source": [
        "What is the predicted rating of `userId` u1 for `movieId` m1?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uSYghu1IlVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3652287-324a-41be-d543-d52111e94d05"
      },
      "source": [
        "print('Predicted rating:', predict_rating_MC('u1', 'm1'))\n",
        "print('Actual rating:', r_df_matrix.loc['u1']['m1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted rating: 4.769198526598024\n",
            "Actual rating: 4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VApK70ld1tQ_"
      },
      "source": [
        "Now answer the questions for Task 3 in the quiz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN_OpdQYHmTb"
      },
      "source": [
        "# Part B - Explicit Matrix Factorisation using Spotlight\n",
        "\n",
        "In this part, we will investigate explicit matrix factorisation.\n",
        "\n",
        "Now we can get onto some real recommendation work. Spotlight has a handy [Interactions](https://maciejkula.github.io/spotlight/interactions.html) object, which encapsulates the basics of a recommendation dataset.\n",
        "\n",
        "In fact, there are handy loaders for a few standard datasets including MovieLens, but let's make our own, so that we can match back to the dataframe.\n",
        "\n",
        "Interactions need numbers as user IDs and item IDs. Unfortunately, our MovieLens uses numbers, but these aren't consecutive (i.e. we have missing `movieId` values). They are also strings (i.e. `movieId` starts with \"m\" and `userId` starts with \"u\").\n",
        "\n",
        "Hence, for both movies and users, we will use [defaultdict](https://docs.python.org/3/library/collections.html#collections.defaultdict) to convert the MovieLens strings down to consecutive integers for use in Spotlight, in the `uid_map` and `iid_map` objects. We'll keep the reverse mapping around too, in case we want to lookup the actual `movieId` given the `uid` recorded by Spotlight (etc).\n",
        "\n",
        "**NB**: This is a really important concept to understand. Put simply, WE -- as humans -- deal with external representations (`userId`, `movieId`, in this dataset prefixed with \"u\" and \"m\" respectively). On the other hand, Spotlight can only deal with integers starting from 0 for both items and users (we call these `iid` and `uid`). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF89PzxNHrHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b9bddd-983d-4585-8b1e-8cd2c9658f8b"
      },
      "source": [
        "uid_map = defaultdict(count().__next__)  # Create userId -> uid mapping dictionary. The next assigned value is the current size.\n",
        "iid_map = defaultdict(count().__next__)  # Ditto for movieId -> iid.\n",
        "\n",
        "# uids is an array of integers corresponding to the userId for every row in ratings_df.\n",
        "# uid_map does the assignment of new uid values, or reusing the uid value assigned for each userId.\n",
        "# Ditto for iids and iid_map\n",
        "uids = np.array([uid_map[uid] for uid in ratings_df['userId'].values], dtype = np.int32)\n",
        "iids = np.array([iid_map[iid] for iid in ratings_df['movieId'].values], dtype = np.int32)\n",
        "\n",
        "# Freeze uid_map and iid_map, so no more mappings are created.\n",
        "uid_map.default_factory = None\n",
        "iid_map.default_factory = None\n",
        "\n",
        "# Reverse them, so we can go from iid (int) to itemId (str)\n",
        "uid_rev_map = {v: k for k, v in uid_map.items()}\n",
        "iid_rev_map = {v: k for k, v in iid_map.items()}\n",
        "\n",
        "# Get ratings and timestamps values.\n",
        "ratings = ratings_df['rating'].values.astype(np.float32)\n",
        "timestamps = ratings_df['timestamp'].values.astype(np.int32)\n",
        "\n",
        "print('%d users %d items' % (len(uid_map), len(iid_map)))\n",
        "print('userId u556 got uid', uid_map['u556'])\n",
        "print('movieId m54001 got iid', iid_map['m54001'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "610 users 9724 items\n",
            "userId u556 got uid 555\n",
            "movieId m54001 got iid 2518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrhni5wSX7QP"
      },
      "source": [
        "Furthemore, we will use user u556 as one of our illustrative users. You will remember from Exercise 1 that the user rated a number of fantasy movies highly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDwZYy2xY3-D"
      },
      "source": [
        "## On towards MF\n",
        "\n",
        "Now let's build a Spotlight [Interactions](https://maciejkula.github.io/spotlight/interactions.html) object. This contains everything that Spotlight needs to train a model. We can split it up randomly into train and test subsets.\n",
        "\n",
        "**NB:** We use a SEED (20) to make our results reproducible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg2tNWwPIBfu"
      },
      "source": [
        "dataset = Interactions(\n",
        "    user_ids = uids,\n",
        "    item_ids = iids,\n",
        "    ratings = ratings,\n",
        "    timestamps = timestamps\n",
        ")\n",
        "\n",
        "train, test = random_train_test_split(dataset, random_state = np.random.RandomState(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1shoeRmWKXxS"
      },
      "source": [
        "Let's see how big the two datasets are. What is the train/test split percentage size? (The default fraction of interactions to place in the test set is 0.2.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "XcjOWJ-qIEge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c29710-cb65-4c57-d46c-141f09d59b54"
      },
      "source": [
        "print(train)\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Interactions dataset (610 users x 9724 items x 80668 interactions)>\n",
            "<Interactions dataset (610 users x 9724 items x 20168 interactions)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBnevuHnT57k"
      },
      "source": [
        "Here, you can see that following the collaborative filtering task model (see Lecture 6), all users and all items are present in both training and test sets.\n",
        "\n",
        "Now, you can think of the Interaction objects are being the partitions of the rating matrix. But we don't store it as a single big matrix. Instead, we record three one-dimensional arrays:\n",
        "\n",
        "- one for the IDs of the users\n",
        "- one for the IDs of the items\n",
        "- one for the actual rating values.\n",
        "\n",
        "Each of these arrays is the size of the number of ratings (80668 for the training set).\n",
        "\n",
        "In essence, Interactions is a sparse matrix - for each rating, we record its x and y position, as well as the rating itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74iQtBOoUZJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008d5a3a-bd6c-4f67-e6a9-19e22fd2c9a8"
      },
      "source": [
        "print(train.item_ids.shape)\n",
        "print(train.user_ids.shape)\n",
        "print(train.ratings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80668,)\n",
            "(80668,)\n",
            "(80668,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V9Hx3dhUjI1"
      },
      "source": [
        "For instance, let's look at the first rating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz46dNMkUrCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3003dae-583c-45a4-ec6f-0527c18bd8e0"
      },
      "source": [
        "print(\"uid %d gave iid %d a rating of %d\" % (train.user_ids[0], train.item_ids[0], train.ratings[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uid 56 gave iid 1491 a rating of 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4R1mQgSUZ86"
      },
      "source": [
        "Let's take our favourite fantasy adventure fan from Exercise 1, `userId` u556. We can give a look at their training ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47QmgWtYvM4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3b0421-2459-447e-ad9f-57867a75e660"
      },
      "source": [
        "user_id = 'u556'\n",
        "uid = uid_map.get(user_id)  # Map userId to the internal uid value.\n",
        "\n",
        "# See which movies and ratings are for this user.\n",
        "print('iid:', train.item_ids[train.user_ids == uid])\n",
        "print('Ratings:', train.ratings[train.user_ids == uid])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iid: [6082 6087  457 1925 7951 1132  764 5989  753 1342 1893 3076 3258 1182\n",
            " 1938 1894 4796  926  770 8659 2059  917 1077  912  779  322 1307 3087\n",
            " 2518  774]\n",
            "Ratings: [4.  3.5 5.  5.  4.  4.  4.  4.  4.5 4.  4.  4.5 4.  4.  4.5 3.5 4.  4.\n",
            " 4.  4.  4.  3.5 5.  2.5 4.  5.  4.  4.  4.  4. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhnKAa-KKclT"
      },
      "source": [
        "We can now learn a model. Let's start with a matrix factorisation for explicit data. We train the Spotlight's [`ExplicitFactorizationModel`](https://maciejkula.github.io/spotlight/factorization/explicit.html#) using the `fit` method. This is just like the `fit` in Sklearn - we're fitting a default model to the specified training data.\n",
        "\n",
        "This might take up to a minute. \n",
        "\n",
        "**NB:** Spotlight can support using GPUs which we could use to slightly speed up training time, but that will make our life more difficult later on, so let's ignore this for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UduCmnlbKt-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78be10f4-e566-462e-ea24-5c17d134ad9c"
      },
      "source": [
        "emodel = ExplicitFactorizationModel(random_state = np.random.RandomState(SEED))\n",
        "current = time.time()\n",
        "emodel.fit(train, verbose = True)\n",
        "end = time.time()\n",
        "print('Training took %d seconds' % (end - current))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 4.3081090674747395\n",
            "Epoch 1: loss 0.8099101063194154\n",
            "Epoch 2: loss 0.5096786571077153\n",
            "Epoch 3: loss 0.3636633798102789\n",
            "Epoch 4: loss 0.2919712789073775\n",
            "Epoch 5: loss 0.25697739233699024\n",
            "Epoch 6: loss 0.23643478482395788\n",
            "Epoch 7: loss 0.22271784451566165\n",
            "Epoch 8: loss 0.2139979781983774\n",
            "Epoch 9: loss 0.20728877597028697\n",
            "Training took 14 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTTK1BlbLL_t"
      },
      "source": [
        "How well did we do? Well, let's give a look at the recommentations, for our specific user, `userId` u556."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjyVPjoGLoy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c012df-d4b2-4bd0-d12f-961053057180"
      },
      "source": [
        "test_item_id = test.item_ids[test.user_ids == uid][0]  # Pick one rating that the user made.\n",
        "movie_id = iid_rev_map.get(test_item_id)  # Map the internal iid value to the movieId.\n",
        "print('One test item ID for userId %s (uid %d) is movieId %s (iid %d)' % (user_id, uid, iid_rev_map.get(test_item_id), test_item_id))\n",
        "\n",
        "predicted = emodel.predict(np.array([uid]), item_ids = np.array([0, test_item_id]))[1]  # Here 0 is a dummy item, which Spotlight needs for some reason. We discard its prediction using [1].\n",
        "actual = ratings_df[(ratings_df['userId'] == user_id) & (ratings_df['movieId'] == movie_id)]['rating'].values[0]  # The actual score of the user for that movie.\n",
        "print('Predicted rating for \"%s\" was %f, actual rating %.1f, error was %f' % (\n",
        "    movies_df[movies_df['movieId'] == movie_id]['title'].values[0],\n",
        "    predicted,\n",
        "    actual,\n",
        "    abs(predicted - actual)\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One test item ID for userId u556 (uid 555) is movieId m74530 (iid 8141)\n",
            "Predicted rating for \"Percy Jackson & the Olympians: The Lightning Thief (2010)\" was 2.574092, actual rating 3.5, error was 0.925908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWdWW8QhacOw"
      },
      "source": [
        "So this is interesting - while we saw above that the users liked fantasy movies, we predicted a rating of $\\sim 2.5$, but the user gave this particular movie a 3.5.\n",
        "\n",
        "We can also ask for **all** of the recommendations for a given user u556."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz28wrmIsDa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd10f46-bb23-495a-8291-974b6a5c8879"
      },
      "source": [
        "allpreds = emodel.predict(np.array([uid]))\n",
        "print(allpreds)\n",
        "print(allpreds.size)\n",
        "print(allpreds[test_item_id])  # Recover the original rating for our test item.\n",
        "print(allpreds[test_item_id] - actual < 0.1)  # Check we got the correct prediction."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.9689248  4.3499784  4.5101566  ... 0.87423515 2.7873065  0.9850692 ]\n",
            "9724\n",
            "2.5740924\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d25P7AtBPgXS"
      },
      "source": [
        "## Latent Factors aka Embeddings\n",
        "\n",
        "Let's see how these recommendations are made. Remember from Lecture 8 that the prediction is made based on the dot product of the user's and item's latent factors (also know as \"embeddings\").\n",
        "\n",
        "We can access these embeddings directly from the `emodel` object. Each embedding has 32 dimensions, which is what Spotlight sets when using the default Explicit Factorisation Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "Jf2Em9KSa74G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a468d83-8012-43c9-c35f-2e0ffa8809fb"
      },
      "source": [
        "# A PyTorch tensor can be thought of having similar semantics as a numpy array.\n",
        "print('Dimension 0 -')\n",
        "print('User embeddings:', emodel._net.user_embeddings.weight[0])\n",
        "print('Movie embeddings:', emodel._net.item_embeddings.weight[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension 0 -\n",
            "User embeddings: tensor([ 0.9949, -0.0203,  0.5183, -0.5834,  0.3204,  0.1194,  0.1783,  0.2095,\n",
            "         0.5180, -0.0313, -0.0679,  0.8740,  0.1025,  0.4426,  0.0245,  0.3884,\n",
            "         0.1170,  0.0406, -0.0458,  0.2030, -0.2486, -0.8601,  0.5501,  0.3770,\n",
            "        -0.0193, -0.2196,  0.2495, -0.1036, -0.4725, -0.5731, -0.3454,  0.4075],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Movie embeddings: tensor([ 0.1223, -0.3951, -0.3488,  0.0474,  0.7867, -0.0242,  0.2448,  0.7672,\n",
            "        -0.1924, -0.0686, -0.1228,  0.6061, -0.1798, -0.3621,  0.7326,  0.2025,\n",
            "        -0.1660, -0.3077, -0.3590, -0.3852,  0.2369, -0.6257,  0.7370,  0.8468,\n",
            "         0.0755, -0.4360, -0.1154, -0.2451, -0.0357, -0.0060,  0.1001,  0.2164],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcKlJIBoVNYr"
      },
      "source": [
        "We can check how Spotlight makes its prediction. The key line is https://github.com/maciejkula/spotlight/blob/master/spotlight/factorization/representations.py#L89.\n",
        "\n",
        "This takes the (dot-)product of the user's \"embedding\" (latent factor) and the item's embedding. On top of these are added \"user_biases\" and \"item_biases\". What do you think these last two components are for? You could refer to [this link](https://stats.stackexchange.com/questions/113390/the-role-of-the-bias-terms-in-matrix-factorization-formulas) for some inspiration.\n",
        "\n",
        "Let's reproduce this for our favourite user u556."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g14v62m4YRyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42976143-d5fc-4f7e-eb0d-96c8473c5794"
      },
      "source": [
        "dotprod = (emodel._net.user_embeddings.weight[uid] * emodel._net.item_embeddings.weight[test_item_id]).sum(0)\n",
        "user_bias = emodel._net.user_biases(torch.tensor([uid]))\n",
        "item_bias = emodel._net.item_biases(torch.tensor([test_item_id], dtype = torch.long))\n",
        "\n",
        "print(movies_df[movies_df['movieId'] == movie_id]['title'].values[0])\n",
        "dotprod + user_bias + item_bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percy Jackson & the Olympians: The Lightning Thief (2010)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.5741]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VE2tpcJb8e7"
      },
      "source": [
        "## Task 4. Examining Latent Factors\n",
        "\n",
        "Let's give a look at item-item similarities. Write a function `most_similar()` that identifies the most similar `movieId` to the specified target, based on the cosine similarity of their item embedding vectors. \n",
        "\n",
        "What's the closest movie to \"Harry Potter and the Deathly Hallows: Part 1 (2010)\" (`movieId` m81834) in the MovieLens dataset?\n",
        "\n",
        "**Hint:**\n",
        "- Since we're working with PyTorch tenors, you should use [`nn.functional.cosine_similarity(x, y, dim = 0)`](https://pytorch.org/docs/stable/nn.functional.html#cosine-similarity) to calculate the cosine similarity between two vectors x & y, as demonstrated below between two orthogonal vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7fDGUx6fBR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8322ac10-9203-4987-b337-2a2830d73710"
      },
      "source": [
        "nn.functional.cosine_similarity(torch.tensor([1., 0]), torch.tensor([0, 1.],), dim = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rg_DuBnoMEu"
      },
      "source": [
        "def most_similar(target_iid: int, model: ExplicitFactorizationModel) -> None:\n",
        "  '''\n",
        "  Locate the most similar movie based on the cosine similarity of the item embedding vectors.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  target_iid : the iid of the target movie\n",
        "  model : the explicit factorisation model\n",
        "  '''\n",
        "\n",
        "  # Initialise the iid with the highest cosine similarity.\n",
        "  highest = 0\n",
        "  highest_cos = 0\n",
        "\n",
        "  # Find the real highest cosine similarity.\n",
        "  for iid, item_embedding in enumerate(model._net.item_embeddings.weight):\n",
        "    if iid != target_iid:\n",
        "      cos = nn.functional.cosine_similarity(model._net.item_embeddings.weight[target_iid], item_embedding, dim = 0).item()\n",
        "\n",
        "      if cos > highest_cos:\n",
        "        highest = iid\n",
        "        highest_cos = cos\n",
        "\n",
        "  target_movie_id = iid_rev_map.get(target_iid)\n",
        "  similar_movie_id = iid_rev_map.get(highest)\n",
        "  print('Target movie \"%s\" (movieId %s, iid %d)' % (\n",
        "      movies_df[movies_df['movieId'] == target_movie_id]['title'].values[0],\n",
        "      target_movie_id,\n",
        "      target_iid))\n",
        "  print('Most similar movie \"%s\" (movieId %s, iid %d) with cosine similarity of %f' % (\n",
        "      movies_df[movies_df['movieId'] == similar_movie_id]['title'].values[0],\n",
        "      similar_movie_id,\n",
        "      highest,\n",
        "      highest_cos))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGY7aqpgHziM"
      },
      "source": [
        "What is the predicted rating for userId u1 for movieId m1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEFpp-36EhMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ae6f88-3dcf-45a9-823f-4a44fcabf258"
      },
      "source": [
        "most_similar(iid_map['m81834'], emodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target movie \"Harry Potter and the Deathly Hallows: Part 1 (2010)\" (movieId m81834, iid 1933)\n",
            "Most similar movie \"Harry Potter and the Half-Blood Prince (2009)\" (movieId m69844, iid 917) with cosine similarity of 0.793590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Br4nChVqUAj"
      },
      "source": [
        "What is the `movieId` and cosine similarity of the most similar movie to m88125?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgUvFR0AK8XI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2b4aff-8e7f-4bf0-fe43-9cc2cf653157"
      },
      "source": [
        "most_similar(iid_map['m88125'], emodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target movie \"Harry Potter and the Deathly Hallows: Part 2 (2011)\" (movieId m88125, iid 1938)\n",
            "Most similar movie \"Harry Potter and the Half-Blood Prince (2009)\" (movieId m69844, iid 917) with cosine similarity of 0.765978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxHfMZgbcdRu"
      },
      "source": [
        "## Evaluating performance\n",
        "\n",
        "Finally, let's see how good we are at our rating predictions. Handily, Spotlight implements a few common evaluation measures for us to inspect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB8UJykycm3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb09e329-92d4-40ff-c0df-f7c8311ad39e"
      },
      "source": [
        "train_rmse = rmse_score(emodel, train)\n",
        "test_rmse = rmse_score(emodel, test)\n",
        "print('Train RMSE {:.3f}, test RMSE {:.3f}'.format(train_rmse, test_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train RMSE 0.421, test RMSE 1.078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcRrTWx9lkoo"
      },
      "source": [
        "## Task 5. Tuning\n",
        "\n",
        "It's appropriate to tune the latent factors. Normally we would use a held-out *validation* for setting the parameters, but as an exercise it is useful to examine performance on the training and test data.\n",
        "\n",
        "The task here is to:\n",
        "\n",
        "- Train and evaluate new instances of `ExplicitFactorizationModel` using different numbers of latent factors, while leaving the other parameters unchanged. Vary the factors in `[8,16,32,64]`.\n",
        "- Record the training time for different numbers of latent factors.\n",
        "- Evaluate and record the RMSE values of the resulting models on both the training and test sets.\n",
        "- Use matplotlib to create a graph showing how training and test RMSE change as the number of latent factors is varied. Use [plt.savefig()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html) to save a PNG of your graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42zBfjCEL6pI",
        "outputId": "6838b88d-23cd-41bf-e003-ec786a9224f9"
      },
      "source": [
        "embedding_dims = [8, 16, 32, 64]  # Define a list of the number of latent factors to vary.\n",
        "training_time_results = []\n",
        "train_rmses = []\n",
        "test_rmses = []\n",
        "\n",
        "# Apply EFM using different numbers of latent factors.\n",
        "for embedding_dim in embedding_dims:\n",
        "  emodel = ExplicitFactorizationModel(embedding_dim = embedding_dim, random_state = np.random.RandomState(SEED))  # Build an EFM.\n",
        "  current = time.time()\n",
        "  emodel.fit(train)  # Fit the model.\n",
        "  end = time.time()\n",
        "  training_time = end - current  # Record the training time.\n",
        "  train_rmse = rmse_score(emodel, train)  # Compute RMSE of the training set.\n",
        "  test_rmse = rmse_score(emodel, test)  # Compute RMSE of the test set.\n",
        "  training_time_results.append(training_time)\n",
        "  train_rmses.append(train_rmse)\n",
        "  test_rmses.append(test_rmse)\n",
        "  print('%d latent factors, training time %d sec, train RMSE %.3f, test RMSE %.3f' % (embedding_dim, training_time, train_rmse, test_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 latent factors, training time 8 sec, train RMSE 0.577, test RMSE 1.011\n",
            "16 latent factors, training time 10 sec, train RMSE 0.483, test RMSE 1.048\n",
            "32 latent factors, training time 14 sec, train RMSE 0.421, test RMSE 1.078\n",
            "64 latent factors, training time 24 sec, train RMSE 0.468, test RMSE 1.038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_VlFV79NWJuY",
        "outputId": "53e1360b-76db-40c8-a250-001b1567aa2f"
      },
      "source": [
        "plt.plot(train_rmses, label = 'Train RMSE', marker = 'o')\n",
        "plt.plot(test_rmses, label = 'Test RMSE', marker = 'o')\n",
        "plt.title('RMSE by the number of latent factors')\n",
        "plt.xlabel('The number of latent factors')\n",
        "plt.xticks(labels = embedding_dims, ticks = np.arange(4))\n",
        "plt.ylabel('RMSE')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "# plt.savefig('task5.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYTtH0_pl6sj"
      },
      "source": [
        "## Evaluating Other Models\n",
        "\n",
        "When evaluating models, it's important to compare to some reasonable baselines. \n",
        "\n",
        "Fortunately, Spotlight's `rmse_score()` method can be used to evaluate any Python object that adheres to the specification of the `predict()` function. For instance, we can make a baseline \"static\" scoring model, which returns the same scores for each user. This set of scores is passed as numpy array in the constructor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Xd1X4TX2Tq"
      },
      "source": [
        "class StaticModel:\n",
        "  '''\n",
        "  The class for a baseline static scoring model.\n",
        "  '''\n",
        "\n",
        "  def __init__(self, static_scores: np.ndarray) -> None:\n",
        "    '''\n",
        "    The constructor of the class for a baseline static scoring model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    static_scores : the static scores\n",
        "    '''\n",
        "\n",
        "    self.n_items = len(static_scores)\n",
        "    self.static_scores = static_scores\n",
        "\n",
        "  def predict(self, uids, iids = None) -> list:\n",
        "    '''\n",
        "    Predict the static scores.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    uids : the user(s) we are requesting recommendations for\n",
        "    iids : the specified item\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    scores : the static scores, one for each item, duplicated for each user requested\n",
        "    '''\n",
        "\n",
        "    uids = [uids] if isinstance(uids, int) else uids  # Respond to one or more uids.\n",
        "    iids = np.arange(self.n_items) if iids is None else iids  # If iid is specificed, we filter predicts for the userId.\n",
        "    return [self.static_scores[iids] for _ in uids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhl_7mUxmdlv"
      },
      "source": [
        "For instance, we can make a static baseline that just returns 0 for every item, regardless of the user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3FVJWJzYhoC",
        "outputId": "8e5e7472-5ded-401e-e347-fcda81844f4b"
      },
      "source": [
        "dummy_model = StaticModel(np.zeros(len(iid_map)))\n",
        "print('Asking for 2 users, 1 item:', dummy_model.predict([0, 1], 0))\n",
        "print('Asking for 1 user, 1 item:', dummy_model.predict(0, 0))\n",
        "print('Asking for 1 user, 2 items:', dummy_model.predict(0, [0, 1]))\n",
        "print('RMSE of our dummy model:', rmse_score(dummy_model, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asking for 2 users, 1 item: [0.0, 0.0]\n",
            "Asking for 1 user, 1 item: [0.0]\n",
            "Asking for 1 user, 2 items: [array([0., 0.])]\n",
            "RMSE of our dummy model: 3.64275783561697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSnTtOzAoA2l"
      },
      "source": [
        "## Task 6. Popularity-based Recommenders\n",
        "\n",
        "This task asks you to implement other baseline recommenders.\n",
        "\n",
        "**Using `ratings_df`**, create 3 new instances of StaticModel as baselines:\n",
        "\n",
        "(a). the number of ratings - you must linearly normalise this to be in the range 0-5.\n",
        "\n",
        "(b). the number of top ratings (i.e., the rating value is 5) received by an item - you must linearly normalise this to be in the range 0-5.\n",
        "\n",
        "(c). the average rating value for each item (no need to normalise - scores are already 0-5)\n",
        "\n",
        "Evaluate your baseline models in terms of RMSE, as well as providing their scores for particular iids, as requested in the quiz.\n",
        "\n",
        "**Hints:**\n",
        "- You may find iterating over a dataframe using `iterrows()` useful - e.g. see https://stackoverflow.com/a/16476974.\n",
        "- You may refer to [this link](https://stats.stackexchange.com/questions/25894/changing-the-scale-of-a-variable-to-0-100) for some inspiration for rescaling.\n",
        "- Order is VERY IMPORTANT. Think carefully about the assumed order that `predict()` returns item scores for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-TjG_2WihCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd19d2d4-c56c-4fe4-d73a-94677051da90"
      },
      "source": [
        "def rescale(n_ratings: np.ndarray) -> np.ndarray:\n",
        "  '''\n",
        "  Rescale the number of ratings to the range 0 - 5.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  n_ratings : the number of ratings for each item\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  n_ratings_rescaled : the rescaled number of ratings for each item.\n",
        "  '''\n",
        "\n",
        "  n_ratings_min = np.min(n_ratings)  # Store MIN_o (o: old).\n",
        "  return 5 / (np.max(n_ratings) - n_ratings_min) * (n_ratings - n_ratings_min)  # (MAX_n - MIN_n) / (MAX_o - MIN_0) * (v - MIN_o) + MIN_n (n: new, v: value).\n",
        "\n",
        "\n",
        "# The assumed item order in StaticModel's predict() is the same as iid_map (i.e., the order of unique movies in ratings_df).\n",
        "# Use \"sort = False\" to preserve the order of unique movies in ratings_df.\n",
        "n_ratings = rescale(ratings_df.groupby(['movieId'], sort = False)['rating'].count().values)  # Get the number of ratings for each item, rescaled to the range 0 - 5.\n",
        "n_top_ratings = rescale(ratings_df.groupby(['movieId'], sort = False)['rating'].apply(lambda rating : (rating == 5).sum()).values)  # Get the number of top ratings for each item, rescaled to the range 0 - 5.\n",
        "mean_ratings = ratings_df.groupby(['movieId'], sort = False)['rating'].mean().values  # Get the mean rating value for each item.\n",
        "\n",
        "# Build the 3 baseline models.\n",
        "model_a = StaticModel(n_ratings)\n",
        "model_b = StaticModel(n_top_ratings)\n",
        "model_c = StaticModel(mean_ratings)\n",
        "\n",
        "# Evaluate RMSE.\n",
        "print('RMSE of Model A:', rmse_score(model_a, test))\n",
        "print('RMSE of Model B:', rmse_score(model_b, test))\n",
        "print('RMSE of Model C:', rmse_score(model_c, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE of Model A: 2.899816663013065\n",
            "RMSE of Model B: 3.3080173160912762\n",
            "RMSE of Model C: 0.8810745544813008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD9DKZGOy2D6"
      },
      "source": [
        "What is the predicted rating of each model for `iid` 0? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGtexrCUy8Ai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d81d92-0799-4be9-d8ef-bb1581c41198"
      },
      "source": [
        "print('Prediction of Model A:', model_a.predict(0, 0))\n",
        "print('Prediction of Model B:', model_b.predict(0, 0))\n",
        "print('Prediction of Model C:', model_c.predict(0, 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction of Model A: [3.2621951219512195]\n",
            "Prediction of Model B: [1.5359477124183007]\n",
            "Prediction of Model C: [3.9209302325581397]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aCiYTWaeobQ"
      },
      "source": [
        "# Part C - Implicit Recommendation\n",
        "\n",
        "This part of the lab uses a music dataset from [Last.fm](https://www.last.fm/) -- a Spotify-like music streaming service -- that was obtained by a researcher at Pompeu Fabra University (Barcelona, Spain). The relevant citation is:\n",
        "\n",
        "```\n",
        "  @book{Celma:Springer2010,\n",
        "      \tauthor = {Celma, O.},\n",
        "      \ttitle = {{Music Recommendation and Discovery in the Long Tail}},\n",
        "       \tpublisher = {Springer},\n",
        "       \tyear = {2010}\n",
        "      }\n",
        " ```\n",
        "\n",
        "You can have more information about the dataset at [this link](http://ocelma.net/MusicRecommendationDataset/lastfm-1K.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsDavoa3qC64"
      },
      "source": [
        "## Dataset preparation\n",
        "\n",
        "This dataset is 600MB copmressed, and 2.4GB uncompressed. It takes 30 seconds to download on Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-drWmULel_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760b52d1-f86f-4565-9bd0-23a3168e873e"
      },
      "source": [
        "!rm -rf lastfm-dataset-1K.tar.gz\n",
        "!curl -o lastfm-dataset-1K.tar.gz http://www.dcs.gla.ac.uk/~craigm/recsysH/lastfm-dataset-1K.tar.gz\n",
        "# !curl -o lastfm-dataset-1K.tar.gz http://macavaney.us/misc/lastfm-dataset-1K.tar.gz  # Backup location. Use it instead of the previous line if necessary.\n",
        "!tar -zxvf lastfm-dataset-1K.tar.gz\n",
        "!ls -lh lastfm-dataset-1K/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  641M  100  641M    0     0  25.4M      0  0:00:25  0:00:25 --:--:-- 25.2M\n",
            "lastfm-dataset-1K/\n",
            "lastfm-dataset-1K/userid-profile.tsv\n",
            "lastfm-dataset-1K/README.txt\n",
            "lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\n",
            "total 2.4G\n",
            "-rw-r--r-- 1 1002 1002 2.2K Mar 23  2010 README.txt\n",
            "-rw-r--r-- 1 1002 1002  37K Dec 30  2009 userid-profile.tsv\n",
            "-rw-r--r-- 1 1002 1002 2.4G Mar  4  2010 userid-timestamp-artid-artname-traid-traname.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcxILh_-h773"
      },
      "source": [
        "listens_df = pd.read_csv('lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv', header = None, names = ['user', 'timestamp', 'artistid', 'artist', 'trackid', 'trackname'], sep = '\\t')\n",
        "\n",
        "# Some tracks don't seem to have artists or track names, so let's drop them for simplicity.\n",
        "listens_df = listens_df[listens_df.artist.notnull()]\n",
        "listens_df = listens_df[listens_df.trackname.notnull()]\n",
        "\n",
        "listens_df = listens_df.sample(n = 200000, random_state = np.random.RandomState(SEED))  # The dataframe is VERY big (19M interactions), so let's just work with a small sample of it (this will mean that effectiveness will be lower, but learning will be MUCH faster)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZSwFnZSgrNU"
      },
      "source": [
        "Let's look at the dataset. Note that the we don't have any explicit ratings by the users. We just know what they interacted with (and when)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAP3dPt-4KMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "785421b5-298c-4703-e28e-97354d5ae602"
      },
      "source": [
        "listens_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>artistid</th>\n",
              "      <th>artist</th>\n",
              "      <th>trackid</th>\n",
              "      <th>trackname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11087179</th>\n",
              "      <td>user_000593</td>\n",
              "      <td>2007-05-14T18:49:03Z</td>\n",
              "      <td>ad996aef-cc1c-42ac-af5c-619c370f4b8a</td>\n",
              "      <td>Emerson, Lake &amp; Palmer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Three Fates (Clotho/Lachesis/Atropos)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1911790</th>\n",
              "      <td>user_000093</td>\n",
              "      <td>2008-08-18T22:04:59Z</td>\n",
              "      <td>8c538f11-c141-4588-8ecb-931083524186</td>\n",
              "      <td>Bloc Party</td>\n",
              "      <td>315a301e-e764-4adf-91c6-e90a22320106</td>\n",
              "      <td>Positive Tension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099786</th>\n",
              "      <td>user_000594</td>\n",
              "      <td>2008-04-06T10:57:45Z</td>\n",
              "      <td>65f4f0c5-ef9e-490c-aee3-909e7ae6b2ab</td>\n",
              "      <td>Metallica</td>\n",
              "      <td>683c89fe-2be8-4ed2-8e58-68b2343cb8d5</td>\n",
              "      <td>Through The Never</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12076983</th>\n",
              "      <td>user_000651</td>\n",
              "      <td>2008-05-10T07:14:45Z</td>\n",
              "      <td>3ca09fae-fdee-4771-bab9-244708515a98</td>\n",
              "      <td>Omarion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ice Box [Orangefuzzz Weather Advisory Radio Mix]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2680461</th>\n",
              "      <td>user_000137</td>\n",
              "      <td>2009-03-11T23:17:22Z</td>\n",
              "      <td>af84ee9f-534a-4f7f-844b-188ba1c47e87</td>\n",
              "      <td>Los Rodríguez</td>\n",
              "      <td>76b83f07-3763-4c17-8d24-28040d85354a</td>\n",
              "      <td>Dulce Condena</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12309850</th>\n",
              "      <td>user_000667</td>\n",
              "      <td>2007-06-27T23:23:24Z</td>\n",
              "      <td>69b39eab-6577-46a4-a9f5-817839092033</td>\n",
              "      <td>Kasabian</td>\n",
              "      <td>47ec6792-3c84-48fc-b3a4-f047de6c6405</td>\n",
              "      <td>By My Side</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16476660</th>\n",
              "      <td>user_000848</td>\n",
              "      <td>2008-05-29T13:09:48Z</td>\n",
              "      <td>9a04dc8c-82f1-457a-a25a-3ff19e1b471e</td>\n",
              "      <td>St. Germain</td>\n",
              "      <td>e4910740-2347-4729-83b1-73360628751a</td>\n",
              "      <td>Rose Rouge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510193</th>\n",
              "      <td>user_000022</td>\n",
              "      <td>2007-11-03T22:28:52Z</td>\n",
              "      <td>0eb6e8c3-1fc6-4624-83fc-a11c0e292a32</td>\n",
              "      <td>Rosemary</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'Ll Match Your Hate (With All Of My Love)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8740990</th>\n",
              "      <td>user_000461</td>\n",
              "      <td>2008-10-12T08:28:12Z</td>\n",
              "      <td>84800c46-2211-43e0-8a87-bdcbecf91932</td>\n",
              "      <td>Aphrodite</td>\n",
              "      <td>17aaf7a5-fee9-48a4-ac3e-a5c35d4a73fb</td>\n",
              "      <td>Summer Breeze</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19046989</th>\n",
              "      <td>user_000998</td>\n",
              "      <td>2005-11-14T22:08:29Z</td>\n",
              "      <td>a74b1b7f-71a5-4011-9441-d0b5e4122711</td>\n",
              "      <td>Radiohead</td>\n",
              "      <td>5616efb3-4c50-40ab-a792-e2e34faae75f</td>\n",
              "      <td>Morning Bell</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 user  ...                                         trackname\n",
              "11087179  user_000593  ...             Three Fates (Clotho/Lachesis/Atropos)\n",
              "1911790   user_000093  ...                                  Positive Tension\n",
              "11099786  user_000594  ...                                 Through The Never\n",
              "12076983  user_000651  ...  Ice Box [Orangefuzzz Weather Advisory Radio Mix]\n",
              "2680461   user_000137  ...                                     Dulce Condena\n",
              "...               ...  ...                                               ...\n",
              "12309850  user_000667  ...                                        By My Side\n",
              "16476660  user_000848  ...                                        Rose Rouge\n",
              "510193    user_000022  ...        I'Ll Match Your Hate (With All Of My Love)\n",
              "8740990   user_000461  ...                                     Summer Breeze\n",
              "19046989  user_000998  ...                                      Morning Bell\n",
              "\n",
              "[200000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLGzG9Rig3E6"
      },
      "source": [
        "## An implicit recommendation approach\n",
        "\n",
        "Let's move away from explicit recommendation to implicit. We will continue using the [Spotlight](https://github.com/maciejkula/spotlight/) toolkit for our recommender. We can construct [Interaction](https://maciejkula.github.io/spotlight/interactions.html) objects for Spotlight in the same way as before. The only difference is that this time we do not record the user's ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcRhNWXzg7LT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f570667c-0cf4-4ac6-8a6e-504b097c55d9"
      },
      "source": [
        "# We can't trust the musicbrainz IDs to exist, so let's build item IDs based on artist & trackname attributes.\n",
        "LFMiid_map = defaultdict(count().__next__)\n",
        "LFMiids = np.array([LFMiid_map[artist + '/' + trackname] for artist, trackname in listens_df[['artist', 'trackname']].values], dtype = np.int32)\n",
        "\n",
        "# Ditto for user IDs.\n",
        "LFMuid_map = defaultdict(count().__next__)\n",
        "LFMuids = np.array([LFMuid_map[uid] for uid in listens_df['user'].values], dtype = np.int32)\n",
        "\n",
        "# Freeze uid_map and iid_map, so no more mappings are created.\n",
        "LFMuid_map.default_factory = None\n",
        "LFMiid_map.default_factory = None\n",
        "\n",
        "LFMuid_rev_map = {v: k for k, v in LFMuid_map.items()}\n",
        "LFMiid_rev_map = {v: k for k, v in LFMiid_map.items()}\n",
        "\n",
        "# We will set Interactions' num_users and num_items here - it's a good practice.\n",
        "imp_dataset = Interactions(user_ids = LFMuids, item_ids = LFMiids, num_users = len(LFMuid_map), num_items = len(LFMiid_map))\n",
        "print(imp_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Interactions dataset (973 users x 125076 items x 200000 interactions)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22dmr7JKqUnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c9f09f-6189-43d2-e02b-25f9506c5188"
      },
      "source": [
        "itrain, itest = random_train_test_split(imp_dataset, random_state = np.random.RandomState(SEED))\n",
        "print(itrain)\n",
        "print(itest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Interactions dataset (973 users x 125076 items x 160000 interactions)>\n",
            "<Interactions dataset (973 users x 125076 items x 40000 interactions)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFQazPPxhG2_"
      },
      "source": [
        "Let's run Spotlight's [`ImplicitFactorizationModel`](https://maciejkula.github.io/spotlight/factorization/implicit.html) on this dataset. Here, we use a *pointwise* loss, which just tries to predict whether the user will like the item or not. It does not use the BPR loss function (more on that later).\n",
        "\n",
        "**Warning**: This dataset is difficult for the learner - this *will* take a few minutes to learn. Use the time to read-on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co3ZwYgkhKvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085e6f34-7453-41ca-f8f6-8716b4d5c6f2"
      },
      "source": [
        "imodel = ImplicitFactorizationModel(n_iter = 5, random_state = np.random.RandomState(SEED))\n",
        "current = time.time()\n",
        "imodel.fit(itrain, verbose = True)\n",
        "end = time.time()\n",
        "print(\"Training took %d seconds\" % (end - current))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 0.9663112537384033\n",
            "Epoch 1: loss 0.4953250964164734\n",
            "Epoch 2: loss 0.19036926743984223\n",
            "Epoch 3: loss 0.11518938970565797\n",
            "Epoch 4: loss 0.08347186335921288\n",
            "Training took 169 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zso4C5wehLog"
      },
      "source": [
        "Again, we can look at the predictions. We make a prediction (a score) for ALL items for user `uid` 0. Note that the scores vary in magnitude - indeed, we're not predicting a rating, we just need to have scores in order to rank the items in descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR_qbWXEhUDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67bbee34-f433-415f-c63f-9fa3d3d05156"
      },
      "source": [
        "print(imodel.predict(0))\n",
        "print(len(imodel.predict(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ -4.757586   5.261482  -9.297717 ...  -9.027796 -11.657988 -13.502052]\n",
            "125076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCQq0oCF_UIu"
      },
      "source": [
        "Now that we have the scores of all items for a given user, we need to identify the top-scored ones, i.e. those that we would present to the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyZ3PyAxhdDF"
      },
      "source": [
        "## Task 7. Track Analysis\n",
        "\n",
        "Write a function `tracks_for_user()` to identify the artist name & track of the top `k` (e.g. 4) items based on their score for a given user index (i.e. 0...964).\n",
        "\n",
        "**Hints:**\n",
        "- You might found [`np.argwhere()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argwhere.html) to be useful. It results only the positions of an array that are True. For instance:\n",
        "```\n",
        ">>> np.argwhere([True, False])\n",
        "array([[0]])\n",
        "```\n",
        "Alternatively, you can sort and then slice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V93_Bxw3MG1F"
      },
      "source": [
        "def tracks_for_user(uid: int = 4, k: int = 10) -> pd.DataFrame:\n",
        "  '''\n",
        "  Identify the artist name and track of the top k items based on their score for a specific user.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  uid : the uid of the user\n",
        "  k : the number of top items kept\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  top_tracks_df : a dataframe containing the top k items and scores\n",
        "  '''\n",
        "\n",
        "  track_scores = imodel.predict(uid)  # Predict scores for tracks.\n",
        "\n",
        "  # Storing the indices that would sort the scores in descending order equals sorting iids since the indices equal iids.\n",
        "  # Keep the top k tracks and corresponding scores.\n",
        "  top_LFMiids = np.argsort(-track_scores)[:k]\n",
        "  top_tracks = [LFMiid_rev_map[LFMiid] for LFMiid in top_LFMiids]\n",
        "  top_scores = track_scores[top_LFMiids][:k]\n",
        "\n",
        "  return pd.DataFrame({\n",
        "      'Rank': np.arange(1, 11),\n",
        "      'Artist/Trackname': top_tracks,\n",
        "      'Score': top_scores\n",
        "  }).set_index('Rank')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy9iplj-B-BJ"
      },
      "source": [
        "What are the top scored 10 tracks recommended for user `uid` 4?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qvp1sKkCAxB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "30a431aa-9fbc-4b4d-c32b-5049352e0ef6"
      },
      "source": [
        "tracks_for_user()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist/Trackname</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rank</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Evanescence/Sweet Sacrifice</td>\n",
              "      <td>13.124245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mgmt/Kids</td>\n",
              "      <td>12.674792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Killers/Bones</td>\n",
              "      <td>12.663386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nelly Furtado/Say It Right</td>\n",
              "      <td>12.464123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Kings Of Leon/Use Somebody</td>\n",
              "      <td>12.436810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Amy Winehouse/Back To Black</td>\n",
              "      <td>12.173255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Red Hot Chili Peppers/The Zephyr Song</td>\n",
              "      <td>11.530579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Radiohead/Fake Plastic Trees</td>\n",
              "      <td>10.859724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Incubus/Drive</td>\n",
              "      <td>10.710403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Him/The Funeral Of Hearts</td>\n",
              "      <td>10.703417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Artist/Trackname      Score\n",
              "Rank                                                  \n",
              "1               Evanescence/Sweet Sacrifice  13.124245\n",
              "2                                 Mgmt/Kids  12.674792\n",
              "3                         The Killers/Bones  12.663386\n",
              "4                Nelly Furtado/Say It Right  12.464123\n",
              "5                Kings Of Leon/Use Somebody  12.436810\n",
              "6               Amy Winehouse/Back To Black  12.173255\n",
              "7     Red Hot Chili Peppers/The Zephyr Song  11.530579\n",
              "8              Radiohead/Fake Plastic Trees  10.859724\n",
              "9                             Incubus/Drive  10.710403\n",
              "10                Him/The Funeral Of Hearts  10.703417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWFSAuQ40p2Y"
      },
      "source": [
        "## Task 8. Artist Analysis\n",
        "\n",
        "Look at the artists actually listened to by `uid` 4, and compare/contrast with the predictions of the recommender. It's useful to examine how many times each artist was listened to.\n",
        "\n",
        "**Hints:**\n",
        "- Use a `groupby()` on a suitable subset of the `listens_df` dataframe. \n",
        "- Sort by descending frequency of listen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2wFfGfcMJcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ad2de9-1327-49b9-fe59-0f59469112b6"
      },
      "source": [
        "listens_df[listens_df['user'] == LFMuid_rev_map[4]].groupby(['artist'])['trackname'].count().rename('count').sort_values(ascending = False)  # Show the frequency of listen for the specific user ID (mapped from uid) in descending order."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "artist\n",
              "Soda Stereo                                39\n",
              "Gustavo Cerati                             36\n",
              "Radiohead                                  31\n",
              "Lucybell                                   27\n",
              "Silvio Rodríguez                           16\n",
              "                                           ..\n",
              "Stone Temple Pilots                         1\n",
              "Ex                                          1\n",
              "Los Prisioneros                             1\n",
              "Em 3,14 Feat Lucybell Y Canal Magdalena     1\n",
              "01 Ain'T My Bitch                           1\n",
              "Name: count, Length: 146, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2FWymqQRxKj"
      },
      "source": [
        "You could observe that `uid` 4 listened frequently to \"Radiohead\" (rank 3), while a Radiohead song is among the top 10 ranked songs in our predicted model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmTNae6Romuk"
      },
      "source": [
        "## Evaluating an implicit recommender\n",
        "\n",
        "We can examine the mean reciprocal rank (MRR) of the implicit model we have learned. We pass it the test set (which contains knowledge of what the user *actually* clicked), as our ground truth. \n",
        "\n",
        "In the second variant, we also pass the training data. Give a look at the  implementation of [`mrr_score()`](https://github.com/cmacdonald/spotlight/blob/master/spotlight/evaluation.py#L8) to understand what it is doing, and why.\n",
        "\n",
        "**Questions for you to consider**\n",
        "- Why is the second score lower? (Scores of known interactions will be set to very low values like `FLOAT_MAX = np.finfo(np.float32).max` and so not affect the RR.)\n",
        "- Would this be the same for all recommendation settings?\n",
        "- In the implementation, why are the scores negated? Why do we use [`rankdata()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html)? (Rank the predictions in descending order to get the highest RR.)\n",
        " \n",
        "We will use the first variant for this Lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLV71LSjt-k2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c337dd-fd73-431a-844b-03a9ce2aeb02"
      },
      "source": [
        "current = time.time()\n",
        "variant_1 = mrr_score(imodel, itest)\n",
        "print(variant_1.mean())\n",
        "end = time.time()\n",
        "print('1st variant: evaluating took %d seconds' % (end - current))\n",
        "\n",
        "current = time.time()\n",
        "print(mrr_score(imodel, itest, train = itrain).mean())\n",
        "end = time.time()\n",
        "print('2nd variant: evaluating took %d seconds' % (end - current))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.03720125940064275\n",
            "1st variant: evaluating took 37 seconds\n",
            "0.008104536778740273\n",
            "2nd variant: evaluating took 37 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjM_kZNtAE2k"
      },
      "source": [
        "How to interpret an MRR score? We know it has a range [0,1] with 1 being best. 1 means, on average across all users, we make a relevant prediction at rank 1; 0.5 means, on average, at rank 2. This is a very rough rule-of-thumb - MRR isn't a linear measure, so a few poor predictions affect the average more than a few good ones.\n",
        "\n",
        "You can now answer all questions for Task 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL2jRiGF2uLb"
      },
      "source": [
        "## Task 9. Listens and Recommendations\n",
        "\n",
        "- Pick the user with the lowest `uid` that has the highest RR (i.e., 1). How many listens (ie. how many times they have listened to any song) do they have in the training dataset?\n",
        "- Similarly, pick the user with the lowest `uid` that has the lowest RR (i.e., 0). How many listens do they have in the training dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6H0l1S6nNcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9890d34-3651-4b71-db1d-6fadd5727a1d"
      },
      "source": [
        "# Get the lowest uid that has the highest/lowest RR.\n",
        "LFMuid_rr_max = np.argmax(variant_1)\n",
        "LFMuid_rr_min = np.argmin(variant_1)\n",
        "\n",
        "# Count the occurrence of unique uids in the training dataset. The count equals the number of listens for a specific user.\n",
        "unique_users, counts = np.unique(itrain.user_ids, return_counts = True)\n",
        "user_count_dict = dict(zip(unique_users, counts))\n",
        "\n",
        "print('The lowest uid that has the highest RR: %d, totally %d listens' % (LFMuid_rr_max, user_count_dict[LFMuid_rr_max]))\n",
        "print('The lowest uid that has the lowest RR: %d, totally %d listens' % (LFMuid_rr_min, user_count_dict[LFMuid_rr_min]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The lowest uid that has the highest RR: 31, totally 757 listens\n",
            "The lowest uid that has the lowest RR: 1, totally 355 listens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU5S-WkvJJP0"
      },
      "source": [
        "Plot a histogram of the distribution of listens for users in the training portion of the LastFM dataset - like in Exercise 1, use matplotlib's histogram functionality, the default number of bins, and use `log = True`. Save the PNG for uploading to the quiz when prompted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YV01IWFJKRc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3de91c94-8f76-4d90-f798-4688e80ca136"
      },
      "source": [
        "plt.hist(counts, log = True)\n",
        "plt.title('Distribution of listens')\n",
        "plt.xlabel('The number of listens')\n",
        "plt.ylabel('The number of users (log)')\n",
        "# plt.savefig('task9.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NMe1e__2XwJ"
      },
      "source": [
        "Many users have very few listens. Let's set 20 listens as a threshold. Let's define users with < 20 listens as cold-start users. What is the MRR for ONLY these users, versus \"normal\" with 20 or more listens?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdo9fbAmLw14"
      },
      "source": [
        "def filter(uids: np.ndarray) -> float:\n",
        "  '''\n",
        "  Filter the test dataset to compute MRR for wanted users.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  uids : the uids of wanted users\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  mrr : the MRR for wanted users\n",
        "  '''\n",
        "\n",
        "  id_filter = np.where(np.isin(itest.user_ids, uids))  # Generate an ID filter for selecting wanted data.\n",
        "  itest_new = Interactions(user_ids = itest.user_ids[id_filter], item_ids = itest.item_ids[id_filter], num_users = len(LFMuid_map), num_items = len(LFMiid_map))  # Filter itest.\n",
        "  return mrr_score(imodel, itest_new).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SpKN7sdI60t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b40eee-d0d5-45cd-f049-a9b006eda226"
      },
      "source": [
        "# Get the uids for cold-start/normal users in the training dataset.\n",
        "cold_uids = unique_users[np.where(counts < 20)]\n",
        "normal_uids = unique_users[np.where(counts >= 20)]\n",
        "\n",
        "# Filter the test dataset to compute MRR for cold-start/normal users.\n",
        "itest_cold_mrr = filter(cold_uids)\n",
        "itest_normal_mrr = filter(normal_uids)\n",
        "\n",
        "print('For %d cold-start users, MRR: %s' % (cold_uids.size, round(itest_cold_mrr, 4)))\n",
        "print('For %d normal users, MRR: %s' % (normal_uids.size, round(itest_normal_mrr, 4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For 161 cold-start users, MRR: 0.0004\n",
            "For 811 normal users, MRR: 0.0368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR_l43rFc7eo"
      },
      "source": [
        "## Task 10. BPR\n",
        "\n",
        "Finally, let's compare the *pointwise* implicit factorisation model with *BPR*. BPR is a very key recommendation model in the literature, which is widely used today as a baseline in many research papers.\n",
        "\n",
        "Train an `ImplicitFactorizationModel` on the training dataset of the LastFM dataset (i.e. `itrain`) using identical settings as before, except adding `loss = 'bpr'`. Record the time taken to train, and then evaluate its effectiveness in terms of MRR. Do NOT use the `train = itrain` argument to `mrr_score()`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oiCB4PuMQ_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f28bff-cbfe-454d-dab4-6e29318ff261"
      },
      "source": [
        "# Build and train an implicit factorisation model with BPR.\n",
        "imodel_bpr = ImplicitFactorizationModel(n_iter = 5, loss = 'bpr', random_state = np.random.RandomState(SEED))\n",
        "current = time.time()\n",
        "imodel_bpr.fit(itrain, verbose = True)\n",
        "end = time.time()\n",
        "print('Training took %d seconds' % (end - current))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: loss 0.4740972354888916\n",
            "Epoch 1: loss 0.14683696522712708\n",
            "Epoch 2: loss 0.024808155296742917\n",
            "Epoch 3: loss 0.014375447143614292\n",
            "Epoch 4: loss 0.01111387666836381\n",
            "Training took 172 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKS1hDJsmfN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f063bc87-4751-4341-d05c-7c24d0a12038"
      },
      "source": [
        "round(mrr_score(imodel_bpr, itest).mean(), 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awTPM_BGcUc0"
      },
      "source": [
        "# End of Exercise\n",
        "\n",
        "As part of your submission, you should complete the Exercise 2 quiz on Moodle.\n",
        "You will need to upload your notebook, complete with the **results** of executing the code (including figures and plots)."
      ]
    }
  ]
}